from data.categories import CAT
from data.config import API_ID, API_HASH, CHANNEL_ID
import asyncio
import json
import pandas as pd
from datetime import datetime, timedelta
import logging
from typing import Dict, List, Tuple, Set, Any
from telethon import TelegramClient
from telethon.tl.types import Channel
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ config
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
CONFIG = {
    'input_file': '../september/data/messages.json',
    'output_files': {
        'raw_data': '../september/data/budget.xlsx',
        'daily': '../september/data/daily_spendings.xlsx',
        'categorized': '../september/data/category_spendings.xlsx',
        'weekday': '../september/data/weekday_spendings.xlsx',
        'uncategorized': '../september/data/not_used_categories.txt'
    },
    'categories': CAT,
    'holidays': ['01.09.2025', 'any_holidays'],
    'telegram': {
        'days_back': 31
    }
}


class PrivateChannelExporter:
    def __init__(self, api_id, api_hash):
        self.api_id = api_id
        self.api_hash = api_hash
        self.client = None

    async def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞"""
        self.client = TelegramClient(
            'private_session', self.api_id, self.api_hash)
        await self.client.start()

    async def get_private_channel(self, channel_identifier):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –ø—Ä–∏–≤–∞—Ç–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞"""
        try:
            if isinstance(channel_identifier, int):
                channel = await self.client.get_entity(channel_identifier)
            elif isinstance(channel_identifier, str):
                channel = await self.client.get_entity(channel_identifier)
            else:
                print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∫–∞–Ω–∞–ª–∞")
                return None

            if isinstance(channel, Channel):
                return channel
            else:
                print("‚ùå –£–∫–∞–∑–∞–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∫–∞–Ω–∞–ª–æ–º")
                return None

        except ValueError as e:
            print(f"‚ùå –ö–∞–Ω–∞–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {e}")
            print("üîç –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –Ω–∞–π—Ç–∏ ID –∫–∞–Ω–∞–ª–∞ —á–µ—Ä–µ–∑ –±–æ—Ç–∞ @username_to_id_bot")
            return None
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞: {e}")
            return None

    async def export_private_messages(self, channel_identifier, days_back=30):
        """–≠–∫—Å–ø–æ—Ä—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –ø—Ä–∏–≤–∞—Ç–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞"""
        if not self.client:
            await self.initialize()

        channel = await self.get_private_channel(channel_identifier)
        if not channel:
            return None

        try:
            full_channel = await self.client.get_entity(channel_identifier)
            participant = await self.client.get_participants(channel, limit=1)
        except Exception as e:
            print(f"‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –∫–∞–Ω–∞–ª—É: {e}")
            print("üìù –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä/—É—á–∞—Å—Ç–Ω–∏–∫ –∫–∞–Ω–∞–ª–∞")
            return None

        since_date = datetime.now() - timedelta(days=days_back)

        messages_data = []

        try:
            async for message in self.client.iter_messages(
                channel,
                offset_date=since_date,
                reverse=True
            ):
                if message:
                    msg_data = {
                        'id': message.id,
                        'date': message.date.isoformat(),
                        'text': message.text or '',
                        'views': getattr(message, 'views', 0)
                    }
                    messages_data.append(msg_data)

                    if len(messages_data) % 20 == 0:
                        print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(messages_data)} —Å–æ–æ–±—â–µ–Ω–∏–π...")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ —Å–æ–æ–±—â–µ–Ω–∏–π: {e}")
            return None

        return messages_data

    async def disconnect(self):
        if self.client:
            await self.client.disconnect()


async def fetch_telegram_data():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Telegram"""
    exporter = PrivateChannelExporter(API_ID, API_HASH)

    try:
        await exporter.initialize()
        messages = await exporter.export_private_messages(CHANNEL_ID, CONFIG['telegram']['days_back'])

        if messages:
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            os.makedirs(os.path.dirname(CONFIG['input_file']), exist_ok=True)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            with open(CONFIG['input_file'], 'w', encoding='utf-8') as f:
                json.dump(messages, f, ensure_ascii=False, indent=2)
            return True
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ Telegram")
            return False

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å Telegram: {e}")
        return False
    finally:
        await exporter.disconnect()


def load_and_parse_json(filepath: str) -> List[Dict[str, Any]]:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–∞—Ä—Å–∏–Ω–≥ JSON —Ñ–∞–π–ª–∞"""

    try:
        with open(filepath, "r", encoding='utf-8') as file:
            data = json.load(file)
    except FileNotFoundError:
        logger.error(f"–§–∞–π–ª {filepath} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        raise
    except json.JSONDecodeError as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        raise

    return data


def extract_transactions_from_json(messages: List[Dict[str, Any]]) -> pd.DataFrame:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –∏–∑ JSON –¥–∞–Ω–Ω—ã—Ö"""

    dates, names, amounts = [], [], []

    for message in messages:
        if not message.get('text') or not message['text'].strip():
            continue

        text = message['text'].strip()
        parts = text.split()
        if len(parts) < 2:
            logger.warning(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Å–æ–æ–±—â–µ–Ω–∏—è: '{text}'")
            continue

        try:
            amount_str = parts[-1]
            name = ' '.join(parts[:-1])
            amount = int(amount_str)

            date_iso = message['date']
            date_obj = datetime.fromisoformat(date_iso.replace('Z', '+00:00'))
            date_str = date_obj.strftime('%d.%m.%Y')

            dates.append(date_str)
            names.append(name)
            amounts.append(amount)

        except ValueError as e:
            logger.warning(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Å—É–º–º—ã –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ '{text}': {e}")
            continue
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è '{text}': {e}")
            continue

    df = pd.DataFrame({
        '–î–∞—Ç–∞': dates,
        '–ö–∞—Ç–µ–≥–æ—Ä–∏—è': names,
        '–°—É–º–º–∞': amounts
    })

    logger.info(f"–°–æ–∑–¥–∞–Ω DataFrame —Å {len(df)} —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º–∏")
    return df


def validate_data(df: pd.DataFrame) -> bool:
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"""

    if df.empty:
        raise ValueError("DataFrame –ø—É—Å—Ç–æ–π - –Ω–µ—Ç —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")

    negative_sums = df[df['–°—É–º–º–∞'] < 0]
    if not negative_sums.empty:
        logger.warning(
            f"–ù–∞–π–¥–µ–Ω—ã –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ —Å—É–º–º—ã: {len(negative_sums)} –∑–∞–ø–∏—Å–µ–π")

    invalid_dates = []
    for date_str in df['–î–∞—Ç–∞'].unique():
        if safe_date_parse(date_str) is None:
            invalid_dates.append(date_str)

    if invalid_dates:
        logger.warning(f"–ù–∞–π–¥–µ–Ω—ã –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞—Ç—ã: {invalid_dates}")

    return True


def safe_date_parse(date_str: str) -> datetime:
    """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –¥–∞—Ç—ã"""
    try:
        return datetime.strptime(date_str, '%d.%m.%Y')
    except ValueError:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞—Ç—ã: {date_str}")
        return None


def calculate_daily_spendings(df: pd.DataFrame) -> pd.DataFrame:
    """–ê–≥—Ä–µ–≥–∞—Ü–∏—è —Ä–∞—Å—Ö–æ–¥–æ–≤ –ø–æ –¥–Ω—è–º"""

    daily = df.groupby('–î–∞—Ç–∞')['–°—É–º–º–∞'].sum().reset_index()
    total_row = pd.DataFrame(
        {'–î–∞—Ç–∞': ['–û–±—â–∞—è —Å—É–º–º–∞'], '–°—É–º–º–∞': [df['–°—É–º–º–∞'].sum()]})
    result = pd.concat([total_row, daily], ignore_index=True)

    return result


def categorize_spendings(df: pd.DataFrame, categories: Dict[str, List[str]]) -> Tuple[pd.DataFrame, Set[str]]:
    """–ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è —Ä–∞—Å—Ö–æ–¥–æ–≤"""

    category_mapping = {}
    for category, keywords in categories.items():
        for keyword in keywords:
            category_mapping[keyword] = category

    uncategorized = set(df['–ö–∞—Ç–µ–≥–æ—Ä–∏—è']) - set(category_mapping.keys())

    if uncategorized:
        uncategorized_file = CONFIG['output_files']['uncategorized']
        with open(uncategorized_file, "w", encoding='utf-8') as f:
            f.write('\n'.join(sorted(uncategorized)))
        logger.info(
            f"–ù–∞–π–¥–µ–Ω—ã –Ω–µ–∫ategor—Ä–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {len(uncategorized)}. –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {uncategorized_file}")

    df['–û—Å–Ω–æ–≤–Ω–∞—è_–∫–∞—Ç–µ–≥–æ—Ä–∏—è'] = df['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'].map(
        category_mapping).fillna('–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
    categorized = df.groupby('–û—Å–Ω–æ–≤–Ω–∞—è_–∫–∞—Ç–µ–≥–æ—Ä–∏—è')['–°—É–º–º–∞'].sum().reset_index()

    return categorized, uncategorized


def analyze_weekdays(daily_df: pd.DataFrame, holidays: List[str]) -> pd.DataFrame:
    """–ê–Ω–∞–ª–∏–∑ —Ä–∞—Å—Ö–æ–¥–æ–≤ –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏"""

    daily_data = daily_df[daily_df['–î–∞—Ç–∞'] != '–û–±—â–∞—è —Å—É–º–º–∞']

    workdays_sum = 0
    weekends_sum = 0
    workdays_count = 0
    weekends_count = 0

    for _, row in daily_data.iterrows():
        date_str = row['–î–∞—Ç–∞']
        amount = row['–°—É–º–º–∞']

        if is_weekend(date_str, holidays):
            weekends_sum += amount
            weekends_count += 1
        else:
            workdays_sum += amount
            workdays_count += 1

    workdays_avg = workdays_sum / workdays_count if workdays_count > 0 else 0
    weekends_avg = weekends_sum / weekends_count if weekends_count > 0 else 0

    result_df = pd.DataFrame({
        '–î–µ–Ω—å': ['–ë—É–¥–Ω–∏–µ', '–í—ã—Ö–æ–¥–Ω—ã–µ', '–°—Ä–µ–¥–Ω–µ–µ –∑–∞ –±—É–¥–Ω–∏', '–°—Ä–µ–¥–Ω–µ–µ –∑–∞ –≤—ã—Ö–æ–¥–Ω—ã–µ'],
        '–°—É–º–º–∞': [workdays_sum, weekends_sum, workdays_avg, weekends_avg]
    })

    return result_df


def is_weekend(date_str: str, holidays: List[str]) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –¥–µ–Ω—å –≤—ã—Ö–æ–¥–Ω—ã–º –∏–ª–∏ –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–º"""
    date_obj = safe_date_parse(date_str)
    if date_obj is None:
        return False

    return date_obj.weekday() >= 5 or date_str in holidays


def export_results(*dataframes: pd.DataFrame) -> None:
    """–≠–∫—Å–ø–æ—Ä—Ç –≤—Å–µ—Ö DataFrame –≤ Excel —Ñ–∞–π–ª—ã"""

    output_files = [
        CONFIG['output_files']['raw_data'],
        CONFIG['output_files']['daily'],
        CONFIG['output_files']['categorized'],
        CONFIG['output_files']['weekday']
    ]

    for df, filename in zip(dataframes, output_files):
        try:
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            os.makedirs(os.path.dirname(filename), exist_ok=True)
            df.to_excel(filename, index=False)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ {filename}: {e}")
            raise


def generate_report(df: pd.DataFrame, categorized_df: pd.DataFrame, weekday_df: pd.DataFrame) -> None:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""

    total_sum = df['–°—É–º–º–∞'].sum()
    total_average = total_sum / len(df['–î–∞—Ç–∞'].unique())

    top_categories = categorized_df.nlargest(
        3, '–°—É–º–º–∞')[['–û—Å–Ω–æ–≤–Ω–∞—è_–∫–∞—Ç–µ–≥–æ—Ä–∏—è', '–°—É–º–º–∞']].values

    print(' ')
    print(' ')
    print(' ')
    print('\n' + "="*50)
    print("–ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ –ü–û –†–ê–°–•–û–î–ê–ú")
    print("="*50)
    print(f"–†–∞—Å—Ö–æ–¥—ã –≤ —ç—Ç–æ–º –º–µ—Å—è—Ü–µ: {total_sum:,} —Ä—É–±.".replace(",", " "))
    print(
        f"–°—Ä–µ–¥–Ω–∏–π —Ä–∞—Å—Ö–æ–¥ –≤ –¥–µ–Ω—å: {int(total_average):,} —Ä—É–±.".replace(",", " "))
    print(f"–í—Å–µ–≥–æ –¥–Ω–µ–π —Å —Ä–∞—Å—Ö–æ–¥–∞–º–∏: {len(df['–î–∞—Ç–∞'].unique())}")
    print(f"–í—Å–µ–≥–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: {len(df)}")

    print(f"\n–¢–æ–ø-3 –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Ä–∞—Å—Ö–æ–¥–æ–≤:")
    for i, (category, amount) in enumerate(top_categories, 1):
        print(f"  {i}. {category}: {amount:,} —Ä—É–±.".replace(",", " "))

    workdays_avg = weekday_df[weekday_df['–î–µ–Ω—å']
                              == '–°—Ä–µ–¥–Ω–µ–µ –∑–∞ –±—É–¥–Ω–∏']['–°—É–º–º–∞'].values[0]
    weekends_avg = weekday_df[weekday_df['–î–µ–Ω—å'] ==
                              '–°—Ä–µ–¥–Ω–µ–µ –∑–∞ –≤—ã—Ö–æ–¥–Ω—ã–µ']['–°—É–º–º–∞'].values[0]

    print(f"\n–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞—Å—Ö–æ–¥–æ–≤:")
    print(
        f"  –°—Ä–µ–¥–Ω–∏–π —Ä–∞—Å—Ö–æ–¥ –≤ –±—É–¥–Ω–∏: {int(workdays_avg):,} —Ä—É–±.".replace(",", " "))
    print(
        f"  –°—Ä–µ–¥–Ω–∏–π —Ä–∞—Å—Ö–æ–¥ –≤ –≤—ã—Ö–æ–¥–Ω—ã–µ: {int(weekends_avg):,} —Ä—É–±.".replace(",", " "))

    difference = weekends_avg - workdays_avg
    if difference > 0:
        print(
            f"  –í –≤—ã—Ö–æ–¥–Ω—ã–µ —Ç—Ä–∞—Ç–∏—Ç–µ –Ω–∞ {int(difference):,} —Ä—É–±. –±–æ–ª—å—à–µ".replace(",", " "))
    else:
        print(
            f"  –í –±—É–¥–Ω–∏ —Ç—Ä–∞—Ç–∏—Ç–µ –Ω–∞ {abs(int(difference)):,} —Ä—É–±. –±–æ–ª—å—à–µ".replace(",", " "))

    print("="*50)
    print(' ')
    print(' ')


def analyze_financial_data():
    """–ê–Ω–∞–ª–∏–∑ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""

    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–∞—Ä—Å–∏–Ω–≥ JSON –¥–∞–Ω–Ω—ã—Ö
        messages = load_and_parse_json(CONFIG['input_file'])
        df = extract_transactions_from_json(messages)

        # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        validate_data(df)

        # –†–∞—Å—á–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤
        daily_df = calculate_daily_spendings(df)
        categorized_df, uncategorized = categorize_spendings(
            df, CONFIG['categories'])
        weekday_df = analyze_weekdays(daily_df, CONFIG['holidays'])

        # –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        export_results(df, daily_df, categorized_df, weekday_df)

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
        generate_report(df, categorized_df, weekday_df)

        return True

    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return False


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""

    # –®–∞–≥ 1: –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Telegram
    telegram_success = await fetch_telegram_data()
    if not telegram_success:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ Telegram. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.")
        return

    # –®–∞–≥ 2: –ê–Ω–∞–ª–∏–∑ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    analysis_success = analyze_financial_data()

    if telegram_success and analysis_success:
        pass
    else:
        print("\n‚ö†Ô∏è –ü—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–µ–Ω —Å –æ—à–∏–±–∫–∞–º–∏")

if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –≥–ª–∞–≤–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
    asyncio.run(main())
